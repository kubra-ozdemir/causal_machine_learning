---
title: "R Notebook"
output: html_notebook
---


# Section 1 Average Effects

```{r}
if (!require("OutcomeWeights")) install.packages("OutcomeWeights", dependencies = TRUE); library(OutcomeWeights)
if (!require("hdm")) install.packages("hdm", dependencies = TRUE); library(hdm)
if (!require("grf")) install.packages("grf", dependencies = TRUE); library(grf)
if (!require("cobalt")) install.packages("cobalt", dependencies = TRUE); library(cobalt)
if (!require("tidyverse")) install.packages("tidyverse", dependencies = TRUE); library(tidyverse)
if (!require("viridis")) install.packages("viridis", dependencies = TRUE); library(viridis)
if (!require("gridExtra")) install.packages("gridExtra", dependencies = TRUE); library(gridExtra)
library(ivmodel)
```


```{r}
library(mice)

imputed_data <- mice(card.data, m = 5, method = "cart", seed = 123)  # Predictive mean matching
data <- complete(imputed_data)
```


```{r}
data<-card.data
data = na.omit(data)
```


```{r}
# Treatment
D = data$enroll
# Instrument
Z = data$nearc2
# Outcome
Y = data$lwage
# Controls
X = model.matrix(~ 0 +  age + fatheduc + motheduc + weight + momdad14 + sinmom14 + step14 + black + smsa + south + smsa66 + wage + KWW + IQ + married + libcrd14 + exper + expersq + region, data = data)
var_nm = c(  "age"   ,   "fatheduc", "motheduc" ,"weight" ,"momdad14"
           ,"sinmom14" ,"step14"  , "black"                     ,"smsa"     ,"south"  ,"smsa66"  , "wage"     ,"KWW"      ,"IQ"      , "married"                    ,"libcrd14" ,"exper"  ,"expersq"  ,"region" )
colnames(X) = var_nm
```

X = model.matrix(~ 0 + nearc2  + nearc4 + age + fatheduc + motheduc + weight + momdad14 + sinmom14 + step14 + reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + reg669 + south66 + black + smsa + south + smsa66 + wage + KWW + IQ + married + libcrd14 + exper + expersq + region, data = card.data)
var_nm = c("nearc2"  , "nearc4"    ,   "age"   ,   "fatheduc", "motheduc" ,"weight" ,"momdad14"
           ,"sinmom14" ,"step14"   ,"reg661"   ,"reg662"   ,"reg663"  , "reg664"   
           ,"reg665"  ,"reg666"   ,"reg667"   ,"reg668"  , "reg669"  , "south66" , "black"                     ,"smsa"     ,"south"  ,"smsa66"  , "wage"     ,"KWW"      ,"IQ"      , "married"                    ,"libcrd14" ,"exper"  ,"expersq"  ,"region" )

### 2 Fold

```{r}
# 2 folds
dml_2f = dml_with_smoother(Y,D,X,Z,
                           n_cf_folds = 2)
results_dml_2f = summary(dml_2f)
plot(dml_2f)
```
```{r}
omega_dml_2f = get_outcome_weights(dml_2f)
cat("ω'Y replicates point etimates?", 
    all.equal(as.numeric(omega_dml_2f$omega %*% Y),
      as.numeric(results_dml_2f[,1])
    ))
```


```{r, echo = F, results='hide'}
# As the `dml_with_smoother()` objects are memory intensive because they store several $N \times N$ smoother matrices, it is convenient to remove the 2-fold one before proceeding. Comment out if you have enough RAM and want to use the objects later on.
rm(dml_2f)
gc()
```



### 5-fold

Run double ML also with 5-fold cross-fitting:

```{r}
# 5 folds
dml_5f = dml_with_smoother(Y,D,X,Z,
                           n_cf_folds = 5)
results_dml_5f = summary(dml_5f)
plot(dml_5f)
```

extract the weights and confirm numerical equivalence:

```{r}
omega_dml_5f = get_outcome_weights(dml_5f)
cat("ω'Y replicates point etimates?", 
    all.equal(as.numeric(omega_dml_5f$omega %*% Y),
      as.numeric(results_dml_5f[,1])
    ))
```


```{r, echo = F, results='hide'}
# As the `dml_with_smoother()` objects are memory intensive because they store several $N \times N$ smoother matrices, it is convenient to remove the 5-fold one before proceeding. Comment out if you have enough RAM and want to use the objects later on.
rm(dml_5f)
gc()
```


## Check covariate balancing

We use the infrastructure of the `cobalt` package to plot Standardized Mean Differences where we need to flip the sign of the untreated outcome weights to make them compatible with the package framework. This is achieved by multiplying the outcome weights by $2 \times D-1$:
gr
```{r, message = F}
threshold = 0.1

create_love_plot = function(title, index) {
  love.plot(
    D ~ X,
    weights = list(
      "2-fold" = omega_dml_2f$omega[index, ] * (2*D-1),
      "5-fold" = omega_dml_5f$omega[index, ] * (2*D-1)
    ),
    position = "bottom",
    title = title,
    thresholds = c(m = threshold),
    var.order = "unadjusted",
    binary = "std",
    abs = TRUE,
    line = TRUE,
    colors = viridis(3), # color-blind-friendly
    shapes = c("circle", "triangle", "diamond")
  )
}

# Now you can call this function for each plot:
love_plot_plr = create_love_plot("PLR", 1)
love_plot_plriv = create_love_plot("PLR-IV", 2)
love_plot_aipw = create_love_plot("AIPW", 3)
love_plot_waipw = create_love_plot("Wald-AIPW", 4)
love_plot_plr
love_plot_plriv
love_plot_aipw
love_plot_waipw
```


Create the combined plot that ends up in the paper as Figure 2:

```{r, results='hide', fig.width=12, fig.height=8}
figure2 = grid.arrange(
  love_plot_plr, love_plot_aipw,
  love_plot_plriv,love_plot_waipw,
  nrow = 2
)
```

## Hetrogenous Effects
```{r}
### Externally calculate outcome nuisance
rf_Y.hat_default = regression_forest(X,Y)
rf_Y.hat_tuned = regression_forest(X,Y,tune.parameters = "all")
Y.hat_default = predict(rf_Y.hat_default)$predictions
Y.hat_tuned = predict(rf_Y.hat_tuned)$predictions
```

```{r}
# And get smoother matrices
S_default = get_forest_weights(rf_Y.hat_default)
S_tuned = get_forest_weights(rf_Y.hat_tuned)
```

```{r}
cat("RF affine smoother?", 
    all.equal(rowSums(as.matrix(S_default)),
      rep(1,length(Y))
    ))
```

```{r}
# Run CF with the pre-specified outcome nuisance 
cf_default = causal_forest(X,Y,D,Y.hat=Y.hat_default)
cf_tuned = causal_forest(X,Y,D,Y.hat=Y.hat_tuned,tune.parameters = "all")
```

```{r}
cates_default = predict(cf_default)$predictions
cates_tuned = predict(cf_tuned)$predictions
```

```{r}
omega_cf_default = get_outcome_weights(cf_default, S = S_default)
omega_cf_tuned = get_outcome_weights(cf_tuned, S = S_tuned)
```

```{r}
cat("ω'Y replicates CATE point estimates (default)?", 
    all.equal(as.numeric(omega_cf_default$omega %*% Y),
      as.numeric(cates_default)
    ))
cat("\nω'Y replicates CATE point estimates (tuned)?", 
    all.equal(as.numeric(omega_cf_tuned$omega %*% Y),
      as.numeric(cates_tuned)
    ))
```
```{r}
cb_cate_default = standardized_mean_differences(X,D,omega_cf_default$omega,X)
cb_cate_tuned = standardized_mean_differences(X,D,omega_cf_tuned$omega,X)

smd_default = t(abs(cb_cate_default[,3,]))
smd_tuned = t(abs(cb_cate_tuned[,3,]))

# Melt the smd_default matrix to long format
df_default_long = melt(smd_default)
df_default_long$Group = "smd_default"  # Add a group identifier

# Melt the smd_tuned matrix to long format
df_tuned_long = melt(smd_tuned)
df_tuned_long$Group = "smd_tuned"  # Add a group identifier

# Combine the two data frames
df_long = rbind(df_default_long, df_tuned_long)

# Rename the columns for clarity
colnames(df_long) = c("Row", "Variable", "Value", "Group")

# Create the ggplot
figure3 = ggplot(df_long, aes(x = factor(Variable, levels = rev(unique(Variable))), y = Value, fill = Group)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(x = element_blank(), y = "Absolute Standardized Mean Differences") +
  scale_fill_manual(values = viridis(2),
                    name = element_blank(),
                    labels = c("default", "tuned")) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") + 
  coord_flip()
figure3
```
```{r}
ivf_default = instrumental_forest(X,Y,D,Z,Y.hat=Y.hat_default)
ivf_tuned = instrumental_forest(X,Y,D,Z,Y.hat=Y.hat_tuned,tune.parameters = "all")
```
```{r}
clates_default = predict(ivf_default)$predictions
clates_tuned = predict(ivf_tuned)$predictions
omega_if_default = get_outcome_weights(ivf_default, S = S_default)
omega_if_tuned = get_outcome_weights(ivf_tuned, S = S_tuned)
cat("ω'Y replicates CLATE point estimates (default)?", 
    all.equal(as.numeric(omega_if_default$omega %*% Y),
      as.numeric(clates_default)
    ))
cat("\nω'Y replicates CLATE point estimates (tuned)?", 
    all.equal(as.numeric(omega_if_tuned$omega %*% Y),
      as.numeric(clates_tuned)
    ))
```

```{r}
cb_clate_default = standardized_mean_differences(X,D,omega_if_default$omega,X)
cb_clate_tuned = standardized_mean_differences(X,D,omega_if_tuned$omega,X)

smd_default = t(abs(cb_clate_default[,3,]))
smd_tuned = t(abs(cb_clate_tuned[,3,]))

# Melt the smd_default matrix to long format
df_default_long = melt(smd_default)
df_default_long$Group = "smd_default"  # Add a group identifier

# Melt the smd_tuned matrix to long format
df_tuned_long = melt(smd_tuned)
df_tuned_long$Group = "smd_tuned"  # Add a group identifier

# Combine the two data frames
df_long = rbind(df_default_long, df_tuned_long)

# Rename the columns for clarity
colnames(df_long) = c("Row", "Variable", "Value", "Group")

# Create the ggplot
ggplot(df_long, aes(x = factor(Variable, levels = rev(unique(Variable))), y = Value, fill = Group)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(x = element_blank(), y = "Absolute Standardized Mean Differences") +
  scale_fill_manual(values = viridis(2),
                    name = element_blank(),
                    labels = c("default", "tuned")) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") + 
  coord_flip()
```

```{r}
data = data.frame(
  value = c(cates_default, cates_tuned,clates_default, clates_tuned),
  category = rep(c("grf CATEs default", "grf CATEs tuned","grf CLATEs default", "grf CLATEs tuned"), each = length(cates_default))
)

ggplot(data, aes(y = category, x = value, fill = category)) +
  geom_boxplot(alpha = 0.7) +
  geom_vline(xintercept = 0, color = "black", linetype = "solid") +
  labs(
    x = "Estimate",
    y = "Estimator/Implementation"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
if (!require("viridis")) install.packages("viridis", dependencies = TRUE); library(viridis)
if (!require("reshape2")) install.packages("reshape2", dependencies = TRUE); library(reshape2)
if (!require("ggridges")) install.packages("ggridges", dependencies = TRUE); library(ggridges)
```


```{r}
# Create the ridge plot
ggplot(data, aes(x = value, y = category, fill = category)) +
  geom_density_ridges(alpha = 0.7, scale = 1) +
  labs(
    x = "Estimate",
    y = "Estimator/Implementation"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
summary_weights_cf_default = summary(omega_cf_default, quiet = TRUE)
summary_weights_cf_tuned = summary(omega_cf_tuned, quiet = TRUE)
summary_weights_if_default = summary(omega_if_default, quiet = TRUE)
summary_weights_if_tuned = summary(omega_if_tuned, quiet = TRUE)

for (i in 1:dim(summary_weights_if_tuned)[3]) {
  # Extract untreated and treated weights for each group
  sum_weights_cf_default_untreated = summary_weights_cf_default[1,,i]
  sum_weights_cf_default_treated = summary_weights_cf_default[2,,i]
  
  sum_weights_cf_tuned_untreated = summary_weights_cf_tuned[1,,i]
  sum_weights_cf_tuned_treated = summary_weights_cf_tuned[2,,i]
  
  sum_weights_if_default_untreated = summary_weights_if_default[1,,i]
  sum_weights_if_default_treated = summary_weights_if_default[2,,i]
  
  sum_weights_if_tuned_untreated = summary_weights_if_tuned[1,,i]
  sum_weights_if_tuned_treated = summary_weights_if_tuned[2,,i]
  
  # Combine all vectors into a single data frame, with a new 'Treatment' column
  df_weights <- data.frame(
    Value = c(
      sum_weights_cf_default_untreated, sum_weights_cf_default_treated,
      sum_weights_cf_tuned_untreated, sum_weights_cf_tuned_treated,
      sum_weights_if_default_untreated, sum_weights_if_default_treated,
      sum_weights_if_tuned_untreated, sum_weights_if_tuned_treated
    ),
    Group = factor(c(
      rep("CF default", length(sum_weights_cf_default_untreated) + length(sum_weights_cf_default_treated)),
      rep("CF tuned", length(sum_weights_cf_tuned_untreated) + length(sum_weights_cf_tuned_treated)),
      rep("IF default", length(sum_weights_if_default_untreated) + length(sum_weights_if_default_treated)),
      rep("IF tuned", length(sum_weights_if_tuned_untreated) + length(sum_weights_if_tuned_treated))
    )),
    Treatment = factor(c(
      rep("Untreated", length(sum_weights_cf_default_untreated)),
      rep("Treated", length(sum_weights_cf_default_treated)),
      rep("Untreated", length(sum_weights_cf_tuned_untreated)),
      rep("Treated", length(sum_weights_cf_tuned_treated)),
      rep("Untreated", length(sum_weights_if_default_untreated)),
      rep("Treated", length(sum_weights_if_default_treated)),
      rep("Untreated", length(sum_weights_if_tuned_untreated)),
      rep("Treated", length(sum_weights_if_tuned_treated))
    ))
  )
  
  # Plot with ggplot and ggridges
  g <- ggplot(df_weights, aes(x = Value, y = Group, fill = Treatment)) +
    geom_boxplot(position = position_dodge(width = 0.75)) +
    labs(x = dimnames(summary_weights_cf_tuned)[[3]][i], y = NULL) +
    theme_minimal() +
    theme(legend.position = "bottom")  # Place legend at the bottom
  print(g)
}

```
